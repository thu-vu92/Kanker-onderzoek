{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (non-ComBat) cohort bias corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import imputation\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ks_2samp as ks2\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from scipy.stats import wasserstein_distance as w1_dist\n",
    "from scipy.stats import energy_distance as w2_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean(x, default='float'):   \n",
    "    non_default = 'int' if default=='float' else 'float'\n",
    "    try:\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        x.dropna(how='all', axis=1, inplace=True)\n",
    "        if default=='float':\n",
    "            x = x * 1.0\n",
    "        else:\n",
    "            x = x * 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        for col in x.columns:\n",
    "            if 'object' in str(x[col].dtypes):\n",
    "                try:\n",
    "                    x[col] = x[col].astype(default)\n",
    "                except:\n",
    "                    try:\n",
    "                        x[col] = x[col].astype(non_default)\n",
    "                    except:\n",
    "                        print(col)\n",
    "                        x[col] = x[col].astype('category')\n",
    "    return x\n",
    "\n",
    "def get_transposed(df, NameRow='GenX', prefix='GenX'):\n",
    "    transposed  = df.T\n",
    "    new_index = transposed.loc[[NameRow]].values.tolist()[0]\n",
    "    transposed.columns = new_index\n",
    "    if prefix is not None:\n",
    "        transposed.columns = [prefix+'_'+_col for _col in transposed.columns.values.tolist()]\n",
    "    return transposed.drop(NameRow, axis=0, inplace=False)\n",
    "       \n",
    "                     \n",
    "def _outliers_modified_z_score(ys, threshold = 3.5):\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    return modified_z_scores, np.where(np.abs(modified_z_scores) > threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time()\n",
    "\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "\n",
    "    return timed\n",
    "\n",
    "# L/S parallelised\n",
    "@timeit\n",
    "def _preprocess_par(df, cohorts = [], \n",
    "                scaler = \"standard\", \n",
    "                bias_removal = False, \n",
    "                col_range = None, \n",
    "                min_cohort_size=10, \n",
    "                qrange=(0.25,0.75),\n",
    "                debug=False,\n",
    "                n_jobs=10,\n",
    "                imputer=None):\n",
    "        \n",
    "        def _norm(cohort, partition=None):\n",
    "            ch = df[partition]==cohort\n",
    "            if sum(ch)<min_cohort_size:\n",
    "                print(\"Skipping cohort {}, because of low sample count: {}\".format(cohort, sum(ch)))\n",
    "            else:\n",
    "                if debug==False:\n",
    "                    try:\n",
    "                        if imputer is not None:                                \n",
    "                            imp = imputation.Imputer(strategy=imputer, axis=0)\n",
    "                            res = scaler.fit_transform(imp.fit_transform(df.loc[ch,gene_columns].values))\n",
    "                        else:\n",
    "                            res = scaler.fit_transform(df.loc[ch,gene_columns].values)\n",
    "                        df.loc[ch,gene_columns] = pd.DataFrame(data=res, index=ch[ch].index, columns=gene_columns)\n",
    "                        print(\"Corrected cohort {}, with {} samples\".format(cohort, sum(ch))) \n",
    "                    except Exception as e:\n",
    "                        print(\"ERROR\", e, \"cohort:\"+cohort)\n",
    "                        print(\"index:\",ch)\n",
    "                        print(\"target:\", df.loc[ch,gene_columns].shape) \n",
    "                        print(\"replacement:\", res.shape)\n",
    "                else:\n",
    "                    for _col in gene_columns: # for debugging\n",
    "                        df_temp = df.loc[ch, _col].copy() \n",
    "                        try:\n",
    "                            df.loc[ch, _col] = (df_temp-df_temp.mean())/df_temp.std()\n",
    "                        except Exception as e:\n",
    "                            print(\"ERROR\", e, \"gene:\"+_col, \"cohort:\"+cohort)\n",
    "            return df[ch]\n",
    "        def _quantile(cohort, partition=None):\n",
    "                ch = df[partition]==cohort\n",
    "                tor = df.loc[ch, gene_columns]\n",
    "                t = tor.T\n",
    "                tqn = _qn(t.values)\n",
    "                df[gene_columns][ch] = tqn.T # pd.DataFrame(data=tqn.T, index=tor.index, columns=gene_columns)\n",
    "                return df[ch]\n",
    "    \n",
    "        if col_range is None:\n",
    "            gene_columns = [_col for _col in df.columns if 'GenX' in _col]  \n",
    "        else:                      \n",
    "            cr = range(col_range[0], col_range[1])\n",
    "            gene_columns = df.columns[cr]\n",
    "        \n",
    "        if len(cohorts)==0:\n",
    "            cohorts = df.batch_number.unique().tolist()\n",
    "        \n",
    "        if scaler == \"standard\":\n",
    "            scaler = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
    "        elif scaler == \"minmax\":\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "        elif scaler == \"maxabs\":\n",
    "            scaler = preprocessing.MaxAbsScaler()\n",
    "        elif scaler == \"robust\":\n",
    "            scaler = preprocessing.RobustScaler(quantile_range=qrange, \n",
    "                                                    with_scaling=True, with_centering=True)\n",
    "        elif scaler in [\"normalizer\", \"normaliser\"]:\n",
    "            scaler = preprocessing.Normalizer()  \n",
    "            \n",
    "        if bias_removal == True:  \n",
    "            print(\"- \"*30, 'Removing cohort biases')    \n",
    "            if scaler != 'quantile':           \n",
    "                results = Parallel(n_jobs=n_jobs)(delayed(_norm)(cohort) for cohort in cohorts)\n",
    "            else:\n",
    "                results = Parallel(n_jobs=n_jobs)(delayed(_quantile)(cohort) for cohort in cohorts)\n",
    "                \n",
    "            print(\"- \"*30, 'Concatenating results')    \n",
    "            df = pd.concat(results)\n",
    "            \n",
    "        else:\n",
    "            ch = df[partition].isin(cohorts)\n",
    "            df.loc[ch,gene_columns] = scaler.fit_transform(df.loc[ch,gene_columns])\n",
    "            \n",
    "        #df = df[df.batch_number.isin(cohorts)]\n",
    "        return df  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "####\n",
    "####\n",
    "pheno_small = pd.read_csv(\"../_docs/Lung_Phenotype_Metadata.txt\", sep=\"\\t\")\n",
    "pheno_large = pd.read_csv(\"../_docs/Lung_Table_Phenotypes.txt\", sep=\"\\t\")\n",
    "pheno_large.set_index('submitter_id.samples', inplace=True)\n",
    "pheno_large['sample_id'] = pheno_large.index\n",
    "pheno_large['gender.demographic'] = pheno_large['gender.demographic'].apply(lambda x: 0 \n",
    "                                                                            if x=='male' else 1 \n",
    "                                                                                if pd.isna(x)==False \n",
    "                                                                                else np.nan)\n",
    "pheno_large = pheno_large.merge(pd.DataFrame(pheno_large.groupby(by='batch_number').size(), \n",
    "                              columns=['batch_size']),\n",
    "                  left_on='batch_number', right_on='batch_number')\n",
    "\n",
    "pheno_large = pheno_large.merge(\n",
    "    pd.DataFrame(pheno_large.groupby(by='batch_number')['gender.demographic']\\\n",
    "                     .mean().reset_index().rename(index=str, columns={'gender.demographic':'gender_mean'})),\n",
    "                  how='left', left_on='batch_number', right_on='batch_number')\n",
    "\n",
    "####\n",
    "####\n",
    "t = pheno_small.groupby(by='PatientID')['Sample Type'].count()\n",
    "double_patients = t[t>1].index.tolist()\n",
    "ref_normal_tumor = pheno_small.loc[pheno_small.PatientID.isin(double_patients)][['SampleID', 'Sample Type', 'PatientID']]\\\n",
    "                                            .sort_values(by='SampleID')\n",
    "pat_cols_primary = list(set(pheno_small.loc[pheno_small['Sample Type'].isin(['Primary Tumor', \n",
    "                                                                             'Recurrent Tumor'])]['SampleID']))\n",
    "\n",
    "####\n",
    "####\n",
    "root_dir = '/media/koekiemonster/DATA-FAST/genetic_expression/hackathon_2/Lung'\n",
    "type_data = pd.read_csv(root_dir+'/HumanMethylation450_meta.csv', engine='c', sep=',',header=7)\n",
    "type_data['RefGene'] = type_data.UCSC_RefGene_Group.str.split(';').apply(lambda x: \n",
    "                                                                         \",\".join(sorted(set(x))) \n",
    "                                                                         if type(x)==list else np.nan)\n",
    "rare_refgene = type_data.RefGene.value_counts().index[type_data.RefGene.value_counts()<100].tolist()\n",
    "type_data['RefGene'][type_data.RefGene.isin(rare_refgene)] = 'uncommon' \n",
    "type_data = type_data[['IlmnID', 'Name', 'Infinium_Design_Type', \n",
    "                       'Color_Channel', 'Relation_to_UCSC_CpG_Island', 'CHR', 'RefGene']]\n",
    "\n",
    "####\n",
    "####\n",
    "gc.collect()\n",
    "sourceDir = \"/media/koekiemonster/DATA-FAST/genetic_expression/hackathon_2\" # \"/media/bramvanes/Extra/DATA/RexR/2018\" #  #\"/media/bramvanes/Extra/DATA/RexR/2018\" #\n",
    "methylation = pd.read_table(sourceDir+\"/Lung/Lung_Methylation.txt\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methylation.set_index('probeID', inplace=True)\n",
    "methylation= _clean(get_transposed(methylation.copy(), axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
