{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (non-ComBat) cohort bias corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import imputation\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ks_2samp as ks2\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from scipy.stats import wasserstein_distance as w1_dist\n",
    "from scipy.stats import energy_distance as w2_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean(x, default='float'):   \n",
    "    non_default = 'int' if default=='float' else 'float'\n",
    "    try:\n",
    "        x.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        x.dropna(how='all', axis=1, inplace=True)\n",
    "        if default=='float':\n",
    "            x = x * 1.0\n",
    "        else:\n",
    "            x = x * 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        for col in x.columns:\n",
    "            if 'object' in str(x[col].dtypes):\n",
    "                try:\n",
    "                    x[col] = x[col].astype(default)\n",
    "                except:\n",
    "                    try:\n",
    "                        x[col] = x[col].astype(non_default)\n",
    "                    except:\n",
    "                        print(col)\n",
    "                        x[col] = x[col].astype('category')\n",
    "    return x\n",
    "\n",
    "def get_transposed(df, NameRow='GenX', prefix='GenX'):\n",
    "    transposed  = df.T\n",
    "    new_index = transposed.loc[[NameRow]].values.tolist()[0]\n",
    "    transposed.columns = new_index\n",
    "    if prefix is not None:\n",
    "        transposed.columns = [prefix+'_'+_col for _col in transposed.columns.values.tolist()]\n",
    "    return transposed.drop(NameRow, axis=0, inplace=False)\n",
    "       \n",
    "                     \n",
    "def _outliers_modified_z_score(ys, threshold = 3.5):\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    return modified_z_scores, np.where(np.abs(modified_z_scores) > threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time()\n",
    "\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "\n",
    "    return timed\n",
    "\n",
    "# L/S parallelised\n",
    "@timeit\n",
    "def _preprocess_par(df, cohorts = [], \n",
    "                scaler = \"standard\", \n",
    "                bias_removal = False, \n",
    "                col_range = None, \n",
    "                min_cohort_size=10, \n",
    "                qrange=(0.25,0.75),\n",
    "                debug=False,\n",
    "                n_jobs=10,\n",
    "                imputer=None):\n",
    "        \n",
    "        def _norm(cohort, partition=None):\n",
    "            ch = df[partition]==cohort\n",
    "            if sum(ch)<min_cohort_size:\n",
    "                print(\"Skipping cohort {}, because of low sample count: {}\".format(cohort, sum(ch)))\n",
    "            else:\n",
    "                if debug==False:\n",
    "                    try:\n",
    "                        if imputer is not None:                                \n",
    "                            imp = imputation.Imputer(strategy=imputer, axis=0)\n",
    "                            res = scaler.fit_transform(imp.fit_transform(df.loc[ch,gene_columns].values))\n",
    "                        else:\n",
    "                            res = scaler.fit_transform(df.loc[ch,gene_columns].values)\n",
    "                        df.loc[ch,gene_columns] = pd.DataFrame(data=res, index=ch[ch].index, columns=gene_columns)\n",
    "                        print(\"Corrected cohort {}, with {} samples\".format(cohort, sum(ch))) \n",
    "                    except Exception as e:\n",
    "                        print(\"ERROR\", e, \"cohort:\"+cohort)\n",
    "                        print(\"index:\",ch)\n",
    "                        print(\"target:\", df.loc[ch,gene_columns].shape) \n",
    "                        print(\"replacement:\", res.shape)\n",
    "                else:\n",
    "                    for _col in gene_columns: # for debugging\n",
    "                        df_temp = df.loc[ch, _col].copy() \n",
    "                        try:\n",
    "                            df.loc[ch, _col] = (df_temp-df_temp.mean())/df_temp.std()\n",
    "                        except Exception as e:\n",
    "                            print(\"ERROR\", e, \"gene:\"+_col, \"cohort:\"+cohort)\n",
    "            return df[ch]\n",
    "        def _quantile(cohort, partition=None):\n",
    "                ch = df[partition]==cohort\n",
    "                tor = df.loc[ch, gene_columns]\n",
    "                t = tor.T\n",
    "                tqn = _qn(t.values)\n",
    "                df[gene_columns][ch] = tqn.T # pd.DataFrame(data=tqn.T, index=tor.index, columns=gene_columns)\n",
    "                return df[ch]\n",
    "    \n",
    "        if col_range is None:\n",
    "            gene_columns = [_col for _col in df.columns if 'GenX' in _col]  \n",
    "        else:                      \n",
    "            cr = range(col_range[0], col_range[1])\n",
    "            gene_columns = df.columns[cr]\n",
    "        \n",
    "        if len(cohorts)==0:\n",
    "            cohorts = df.batch_number.unique().tolist()\n",
    "        \n",
    "        if scaler == \"standard\":\n",
    "            scaler = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
    "        elif scaler == \"minmax\":\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "        elif scaler == \"maxabs\":\n",
    "            scaler = preprocessing.MaxAbsScaler()\n",
    "        elif scaler == \"robust\":\n",
    "            scaler = preprocessing.RobustScaler(quantile_range=qrange, \n",
    "                                                    with_scaling=True, with_centering=True)\n",
    "        elif scaler in [\"normalizer\", \"normaliser\"]:\n",
    "            scaler = preprocessing.Normalizer()  \n",
    "            \n",
    "        if bias_removal == True:  \n",
    "            print(\"- \"*30, 'Removing cohort biases')    \n",
    "            if scaler != 'quantile':           \n",
    "                results = Parallel(n_jobs=n_jobs)(delayed(_norm)(cohort) for cohort in cohorts)\n",
    "            else:\n",
    "                results = Parallel(n_jobs=n_jobs)(delayed(_quantile)(cohort) for cohort in cohorts)\n",
    "                \n",
    "            print(\"- \"*30, 'Concatenating results')    \n",
    "            df = pd.concat(results)\n",
    "            \n",
    "        else:\n",
    "            ch = df[partition].isin(cohorts)\n",
    "            df.loc[ch,gene_columns] = scaler.fit_transform(df.loc[ch,gene_columns])\n",
    "            \n",
    "        #df = df[df.batch_number.isin(cohorts)]\n",
    "        return df  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (2,4,11,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14943841771c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0msourceDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/media/koekiemonster/DATA-FAST/genetic_expression/hackathon_2\"\u001b[0m \u001b[0;31m# \"/media/bramvanes/Extra/DATA/RexR/2018\" #  #\"/media/bramvanes/Extra/DATA/RexR/2018\" #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmethylation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourceDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/Lung/Lung_Methylation.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n\u001b[1;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "####\n",
    "####\n",
    "pheno_small = pd.read_csv(\"../_docs/Lung_Phenotype_Metadata.txt\", sep=\"\\t\")\n",
    "pheno_large = pd.read_csv(\"../_docs/Lung_Table_Phenotypes.txt\", sep=\"\\t\")\n",
    "pheno_large.set_index('submitter_id.samples', inplace=True)\n",
    "pheno_large['sample_id'] = pheno_large.index\n",
    "pheno_large['gender.demographic'] = pheno_large['gender.demographic'].apply(lambda x: 0 \n",
    "                                                                            if x=='male' else 1 \n",
    "                                                                                if pd.isna(x)==False \n",
    "                                                                                else np.nan)\n",
    "pheno_large = pheno_large.merge(pd.DataFrame(pheno_large.groupby(by='batch_number').size(), \n",
    "                              columns=['batch_size']),\n",
    "                  left_on='batch_number', right_on='batch_number')\n",
    "\n",
    "pheno_large = pheno_large.merge(\n",
    "    pd.DataFrame(pheno_large.groupby(by='batch_number')['gender.demographic']\\\n",
    "                     .mean().reset_index().rename(index=str, columns={'gender.demographic':'gender_mean'})),\n",
    "                  how='left', left_on='batch_number', right_on='batch_number')\n",
    "\n",
    "####\n",
    "####\n",
    "t = pheno_small.groupby(by='PatientID')['Sample Type'].count()\n",
    "double_patients = t[t>1].index.tolist()\n",
    "ref_normal_tumor = pheno_small.loc[pheno_small.PatientID.isin(double_patients)][['SampleID', 'Sample Type', 'PatientID']]\\\n",
    "                                            .sort_values(by='SampleID')\n",
    "pat_cols_primary = list(set(pheno_small.loc[pheno_small['Sample Type'].isin(['Primary Tumor', \n",
    "                                                                             'Recurrent Tumor'])]['SampleID']))\n",
    "\n",
    "####\n",
    "####\n",
    "root_dir = '/media/koekiemonster/DATA-FAST/genetic_expression/hackathon_2/Lung'\n",
    "type_data = pd.read_csv(root_dir+'/HumanMethylation450_meta.csv', engine='c', sep=',',header=7)\n",
    "type_data['RefGene'] = type_data.UCSC_RefGene_Group.str.split(';').apply(lambda x: \n",
    "                                                                         \",\".join(sorted(set(x))) \n",
    "                                                                         if type(x)==list else np.nan)\n",
    "rare_refgene = type_data.RefGene.value_counts().index[type_data.RefGene.value_counts()<100].tolist()\n",
    "type_data['RefGene'][type_data.RefGene.isin(rare_refgene)] = 'uncommon' \n",
    "type_data = type_data[['IlmnID', 'Name', 'Infinium_Design_Type', \n",
    "                       'Color_Channel', 'Relation_to_UCSC_CpG_Island', 'CHR', 'RefGene']]\n",
    "\n",
    "####\n",
    "####\n",
    "gc.collect()\n",
    "sourceDir = \"/media/koekiemonster/DATA-FAST/genetic_expression/hackathon_2\" # \"/media/bramvanes/Extra/DATA/RexR/2018\" #  #\"/media/bramvanes/Extra/DATA/RexR/2018\" #\n",
    "methylation = pd.read_table(sourceDir+\"/Lung/Lung_Methylation.txt\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methylation.set_index('probeID', inplace=True)\n",
    "methylation= _clean(get_transposed(methylation.copy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
